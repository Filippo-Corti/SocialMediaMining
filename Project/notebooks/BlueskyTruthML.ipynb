{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:38:27.600953Z",
     "start_time": "2025-06-04T16:38:08.872374Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from Project.utils.storage import truth_db as t_db\n",
    "from Project.utils.storage import bluesky_db as b_db\n",
    "\n",
    "\n",
    "importlib.reload(t_db)\n",
    "importlib.reload(b_db)\n",
    "\n",
    "\n",
    "truth_db = t_db.SQLiteTruthSaver(db_name='../db/truthsocial.db')\n",
    "bluesky_db = b_db.SQLiteBlueSkySaver(db_name='../db/bluesky.db')"
   ],
   "id": "8212118c6788bfd3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Filippo Corti\\miniconda3\\envs\\SocialMediaMining\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-04T14:30:52.919630Z",
     "start_time": "2025-06-04T14:30:52.916317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# THE PLAN:\n",
    "\n",
    "# 1. Label some comments from both socials, with Gemini\n",
    "\n",
    "# 2. Fine tune a HuggingFace model\n",
    "\n",
    "# 3. Run the model, don't care about performance honestly\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:38:28.630602Z",
     "start_time": "2025-06-04T16:38:27.604988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "truth_db.cursor.execute(\"\"\"\n",
    "SELECT content, gemini_label\n",
    "FROM Posts NATURAL JOIN CommentAnalysis\n",
    "\"\"\")\n",
    "truth_data = truth_db.cursor.fetchall()\n",
    "\n",
    "bluesky_db.cursor.execute(\"\"\"\n",
    "SELECT content, gemini_label\n",
    "FROM Posts NATURAL JOIN CommentAnalysis\n",
    "\"\"\")\n",
    "bluesky_data = bluesky_db.cursor.fetchall()\n",
    "\n",
    "data = truth_data + bluesky_data\n",
    "\n",
    "df = pd.DataFrame(data, columns=['content', 'label'])\n",
    "df['label'] = [{'Neutral': 0, 'Republican': 1, 'Democratic': 2}.get(l) for l in df['label']]"
   ],
   "id": "b6c45f07d0036cb4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:38:31.310706Z",
     "start_time": "2025-06-04T16:38:31.292522Z"
    }
   },
   "cell_type": "code",
   "source": "df",
   "id": "36b3b35846826e5b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                content  label\n",
       "0                                         <p>Score!</p>      0\n",
       "1                  <p>The 170 can make maple syrup!</p>      0\n",
       "2     <p>Exactly and theyâ€™re not just in one party !...      0\n",
       "3                           <p>why dont you go away</p>      0\n",
       "4     <p>Democrats are destroying America. Why? Is i...      1\n",
       "...                                                 ...    ...\n",
       "4395  California led the way on this one. Donâ€™t forg...      0\n",
       "4396  ðŸ“ŒI see Gavin Newsom saying that a man who is r...      2\n",
       "4397  That's the point. So there's nothing left but ...      2\n",
       "4398  A stroller does not have to cost a thousand bu...      0\n",
       "4399  Anna Wintour rolled up to the South Lawn to di...      0\n",
       "\n",
       "[4400 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;Score!&lt;/p&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;p&gt;The 170 can make maple syrup!&lt;/p&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;Exactly and theyâ€™re not just in one party !...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p&gt;why dont you go away&lt;/p&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;Democrats are destroying America. Why? Is i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4395</th>\n",
       "      <td>California led the way on this one. Donâ€™t forg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>ðŸ“ŒI see Gavin Newsom saying that a man who is r...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>That's the point. So there's nothing left but ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>A stroller does not have to cost a thousand bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>Anna Wintour rolled up to the South Lawn to di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4400 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:38:39.634963Z",
     "start_time": "2025-06-04T16:38:39.622809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['label']  # Ensures balanced splits\n",
    ")\n",
    "\n",
    "print(f\"Train size: {len(train_df)}, Test size: {len(test_df)}\")"
   ],
   "id": "6e3b7d3a8f71a551",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3520, Test size: 880\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:38:46.539005Z",
     "start_time": "2025-06-04T16:38:44.486215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model\n",
    "model_name = \"matous-volf/political-leaning-politics\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3  # 0, 1, 2\n",
    ")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"launch/POLITICS\", use_fast=False)\n",
    "def tokenize_function(data):\n",
    "    return tokenizer(\n",
    "        data['content'],\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512\n",
    "    )"
   ],
   "id": "93739759e3908f9e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:39:00.583189Z",
     "start_time": "2025-06-04T16:38:54.267310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n"
   ],
   "id": "4bd81be11464a3d2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3520/3520 [00:02<00:00, 1365.87 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 880/880 [00:00<00:00, 1227.19 examples/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:39:07.091217Z",
     "start_time": "2025-06-04T16:39:07.075928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class_weights = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(train_df['label']),\n",
    "    y=train_df['label']\n",
    ")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "print(f\"Class weights: {class_weights}\")"
   ],
   "id": "6fe77e234a4ed3a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([0.5090, 2.1295, 1.7671])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:39:12.152203Z",
     "start_time": "2025-06-04T16:39:10.712747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    report = classification_report(labels, predictions, output_dict=True)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_macro': report['macro avg']['f1-score'],\n",
    "        'f1_weighted': report['weighted avg']['f1-score']\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    logging_dir='./logs',\n",
    "    num_train_epochs=3,\n",
    "    warmup_steps=100,                   # Start with a smaller LR\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    weight_decay=0.01,                  # Regularization\n",
    "    eval_steps=200,                     # How often it does evaluation\n",
    "    eval_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_macro\",\n",
    "    greater_is_better=True,             # Needed if metric is f1 instead of loss\n",
    "    report_to=None,\n",
    ")\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ],
   "id": "1bf972ba8aee4c69",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Filippo Corti\\AppData\\Local\\Temp\\ipykernel_31596\\152238528.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T16:59:51.234125Z",
     "start_time": "2025-06-04T16:39:25.033749Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "ae008e50f5652d2b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1320' max='1320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1320/1320 20:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.673560</td>\n",
       "      <td>0.718182</td>\n",
       "      <td>0.555087</td>\n",
       "      <td>0.678162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.860501</td>\n",
       "      <td>0.661364</td>\n",
       "      <td>0.617458</td>\n",
       "      <td>0.678215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.738700</td>\n",
       "      <td>0.834527</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>0.687885</td>\n",
       "      <td>0.751763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.738700</td>\n",
       "      <td>0.772857</td>\n",
       "      <td>0.726136</td>\n",
       "      <td>0.682134</td>\n",
       "      <td>0.737337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.501100</td>\n",
       "      <td>0.971516</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.676428</td>\n",
       "      <td>0.721736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.501100</td>\n",
       "      <td>1.080729</td>\n",
       "      <td>0.692045</td>\n",
       "      <td>0.651945</td>\n",
       "      <td>0.705056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1320, training_loss=0.5616306940714518, metrics={'train_runtime': 1225.9534, 'train_samples_per_second': 8.614, 'train_steps_per_second': 1.077, 'total_flos': 2778477691207680.0, 'train_loss': 0.5616306940714518, 'epoch': 3.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T17:00:42.189395Z",
     "start_time": "2025-06-04T17:00:23.625325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\")\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value}\")"
   ],
   "id": "2d645e4d37263ff8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 00:18]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "eval_loss: 0.8345268964767456\n",
      "eval_accuracy: 0.7454545454545455\n",
      "eval_f1_macro: 0.6878851613264981\n",
      "eval_f1_weighted: 0.7517625157383435\n",
      "eval_runtime: 18.5469\n",
      "eval_samples_per_second: 47.447\n",
      "eval_steps_per_second: 5.931\n",
      "epoch: 3.0\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T17:05:18.208554Z",
     "start_time": "2025-06-04T17:05:17.012937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save model\n",
    "model.save_pretrained('../data/bluesky_truth_model')\n",
    "tokenizer.save_pretrained('../data/bluesky_truth_model')"
   ],
   "id": "3efe267f578433f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/bluesky_truth_model\\\\tokenizer_config.json',\n",
       " '../data/bluesky_truth_model\\\\special_tokens_map.json',\n",
       " '../data/bluesky_truth_model\\\\vocab.json',\n",
       " '../data/bluesky_truth_model\\\\merges.txt',\n",
       " '../data/bluesky_truth_model\\\\added_tokens.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
