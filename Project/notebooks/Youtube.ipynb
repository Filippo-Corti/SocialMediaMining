{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-12T16:32:53.609998Z",
     "start_time": "2025-05-12T16:32:44.263588Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "from Project.utils.storage.youtube_db import SQLiteYoutubeSaver\n",
    "from Project.utils.api.youtube_api import YoutubeApi\n",
    "from Project.utils.analysis.text_classifier import TextClassifier"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Filippo Corti\\miniconda3\\envs\\SocialMediaMining\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T16:32:53.642007Z",
     "start_time": "2025-05-12T16:32:53.634958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "credentials = json.load(open('../../keys/youtube_key.json'))\n",
    "\n",
    "api_key = credentials['api_key']\n",
    "\n",
    "trump_podcasts = [\n",
    "    \"xrFdHO7FH8w\",\n",
    "    \"blqIZGXWUpU\",\n",
    "    \"s11uIW7wi-E\",\n",
    "    \"vC5cHjcgt5g\",\n",
    "    \"G80iLTctFuY\",\n",
    "    \"qCbfTN-caFI\",\n",
    "    \"Ry1IjOft95c\",\n",
    "    \"S7BTdUaNQM8\",\n",
    "    \"1SsmPh8gCxU\",\n",
    "    \"-dmwG54QsKc\",\n",
    "    \"nwQil7tcImI\",\n",
    "    \"G9lXnwuZ2qs\",\n",
    "    \"hBMoPUAeLnY\"\n",
    "]\n",
    "\n",
    "harris_podcasts = [\n",
    "    \"_KCRsjPCiCI\",\n",
    "    \"bzThwqnQJDY\",\n",
    "    \"7L4sts7I3xI\",\n",
    "    \"pNbwMrBMGgE\",\n",
    "    \"Vu5yD3fu6A8\",\n",
    "]"
   ],
   "id": "2593c303f04f2635",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T16:32:53.962879Z",
     "start_time": "2025-05-12T16:32:53.945959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "youtube = YoutubeApi(api_key)\n",
    "youtube_db = SQLiteYoutubeSaver(db_name='../db/youtube.db')"
   ],
   "id": "a218fd1d6b0fbf40",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T07:41:29.941998Z",
     "start_time": "2025-04-25T07:41:28.573079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "videos = [\n",
    "    youtube.get_video_by_id(video_id)\n",
    "    for video_id in trump_podcasts + harris_podcasts\n",
    "]"
   ],
   "id": "4487e838bf70dcca",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:22:35.271406Z",
     "start_time": "2025-04-25T08:22:35.267469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for video in videos:\n",
    "    print(f\"{video.channel_title} - {video.title}\")"
   ],
   "id": "e715b60d754e9ab5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPAULSIVE - The Donald Trump Interview - IMPAULSIVE EP. 418\n",
      "All-In Podcast - In conversation with President Trump\n",
      "Adin Live - Adin Ross & Donald Trump FULL STREAM!\n",
      "Theo Von - Donald Trump | This Past Weekend w/ Theo Von #526\n",
      "Shawn Ryan Show - President Donald J. Trump - 47th President of the United States | SRS #127\n",
      "Lex Fridman - Donald Trump Interview | Lex Fridman Podcast #442\n",
      "FLAGRANT - Trump On Who Really Tried to Kill Him, Abortion & More\n",
      "FULL SEND PODCAST - Donald Trump Calls Out Kamala Over FAKE Interview, Talks Joe Rogan, and Why He HATES Jimmy Kimmel!\n",
      "Bussin' With The Boys - Donald Trump On How Success Will Unite America + The Future Of Media\n",
      "PBD Podcast - Donald Trump Reveals His Next 5 Moves - Speaks On Tariffs, Obama & Iran | PBD Podcast | 489\n",
      "OutKick - \"Manhood Is Under ATTACK!\" Why Donald Trump Keeps Fighting For America | Maintaining with Tyrus\n",
      "Six Feet Under with Mark Calaway - Donald Trump Talks Pro Wrestling and Whatâ€™s at Stake in 2024 | Six Feet Under #36\n",
      "PowerfulJRE - Joe Rogan Experience #2219 - Donald Trump\n",
      "Call Her Daddy - Vice President Kamala Harris\n",
      "ALL THE SMOKE - Vice President Kamala Harris Interview | All the Smoke Special Edition\n",
      "Breakfast Club Power 105.1 FM - We The People Town Hall With Kamala Harris & Charlamagne Tha God\n",
      "The Howard Stern Show - Vice President Kamala Harris on the Howard Stern Show (FULL INTERVIEW)\n",
      "Club Shay Shay - Kamala Harris' Advice To 18-Year-Old Self, Talks Student Loans, Stimulus Checks, HBCU & Donald Trump\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for video in videos:\n",
    "    youtube_db.insert_video(video)\n",
    "    print(f\"Extracting comments from {video.channel_title} - {video.title}\")\n",
    "    for comment in youtube.get_comments(video.id, threads_count=1000):\n",
    "        youtube_db.insert_comment(comment)"
   ],
   "id": "3204c1a35083b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T16:32:56.467248Z",
     "start_time": "2025-05-12T16:32:55.289557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_classifier = TextClassifier()\n",
    "\n",
    "all_comments = youtube_db.get_all_comments()"
   ],
   "id": "43f4730b36e09f08",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T16:32:56.485178Z",
     "start_time": "2025-05-12T16:32:56.481464Z"
    }
   },
   "cell_type": "code",
   "source": "print(len(all_comments))",
   "id": "56ffe39223609a99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114712\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-12T19:12:13.579768Z",
     "start_time": "2025-05-12T18:31:57.094263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "current_batch = list() # Technically not a batch\n",
    "\n",
    "for idx, comment in enumerate(all_comments):\n",
    "\n",
    "    current_batch.append(comment)\n",
    "\n",
    "    if len(current_batch) < 100:\n",
    "        continue\n",
    "\n",
    "    # biases = text_classifier.get_political_bias(\n",
    "    #     [comment.content for comment in current_batch]\n",
    "    # )\n",
    "    # leanings = text_classifier.get_political_leaning( # --> This is not done\n",
    "    #     [comment.content for comment in current_batch]\n",
    "    # )\n",
    "    is_politicals = text_classifier.is_political(\n",
    "        [comment.content for comment in current_batch]\n",
    "    )\n",
    "    # sentiments = text_classifier.get_sentiment(\n",
    "    #     [comment.content for comment in current_batch]\n",
    "    # )\n",
    "    # emotions = text_classifier.get_emotion(\n",
    "    #     [comment.content for comment in current_batch]\n",
    "    # )\n",
    "    # llm_labels = text_classifier.get_llm_political_stance(\n",
    "    #     candidates=[\"Trump\" if comment.video_id in trump_podcasts else \"Harris\" for comment in current_batch],\n",
    "    #     texts=[comment.content for comment in current_batch]\n",
    "    # )\n",
    "\n",
    "    for i in range(len(current_batch)):\n",
    "        comment_id = current_batch[i].id\n",
    "        #bias = biases[i]\n",
    "        #leaning = leanings[i]\n",
    "        is_political = is_politicals[i]\n",
    "        #sentiment = sentiments[i]\n",
    "        #emotion = emotions[i]\n",
    "        #llm_label = llm_labels[i]\n",
    "\n",
    "        youtube_db.insert_comment_analysis(\n",
    "            comment_id=comment_id,\n",
    "            #bias=bias,\n",
    "            #leaning=leaning,\n",
    "            is_political=is_political,\n",
    "            #sentiment=sentiment,\n",
    "            #emotion=emotion,\n",
    "            #llm_label=llm_label,\n",
    "        )\n",
    "\n",
    "    current_batch = list()\n",
    "\n",
    "    idx += 1\n",
    "    if idx % 1000 == 0:\n",
    "        print(f\"{idx}/{len(all_comments)}\")"
   ],
   "id": "11dbf6fdc7e72699",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/114712\n",
      "2000/114712\n",
      "3000/114712\n",
      "4000/114712\n",
      "5000/114712\n",
      "6000/114712\n",
      "7000/114712\n",
      "8000/114712\n",
      "9000/114712\n",
      "10000/114712\n",
      "11000/114712\n",
      "12000/114712\n",
      "13000/114712\n",
      "14000/114712\n",
      "15000/114712\n",
      "16000/114712\n",
      "17000/114712\n",
      "18000/114712\n",
      "19000/114712\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 16\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# biases = text_classifier.get_political_bias(\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m#     [comment.content for comment in current_batch]\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# )\u001B[39;00m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;66;03m# leanings = text_classifier.get_political_leaning( # --> This is not done\u001B[39;00m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m#     [comment.content for comment in current_batch]\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# )\u001B[39;00m\n\u001B[1;32m---> 16\u001B[0m is_politicals \u001B[38;5;241m=\u001B[39m text_classifier\u001B[38;5;241m.\u001B[39mis_political(\n\u001B[0;32m     17\u001B[0m     [comment\u001B[38;5;241m.\u001B[39mcontent \u001B[38;5;28;01mfor\u001B[39;00m comment \u001B[38;5;129;01min\u001B[39;00m current_batch]\n\u001B[0;32m     18\u001B[0m )\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# sentiments = text_classifier.get_sentiment(\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m#     [comment.content for comment in current_batch]\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# )\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;66;03m#     texts=[comment.content for comment in current_batch]\u001B[39;00m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# )\u001B[39;00m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(current_batch)):\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\SocialMediaMining\\Project\\utils\\analysis\\text_classifier.py:77\u001B[0m, in \u001B[0;36mTextClassifier.is_political\u001B[1;34m(self, texts)\u001B[0m\n\u001B[0;32m     74\u001B[0m texts \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtext\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m </s> \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhypothesis\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m text \u001B[38;5;129;01min\u001B[39;00m texts]\n\u001B[0;32m     76\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 77\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_political_pipeline(texts, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     78\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     79\u001B[0m     \u001B[38;5;28mprint\u001B[39m(e)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\SocialMediaMining\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:159\u001B[0m, in \u001B[0;36mTextClassificationPipeline.__call__\u001B[1;34m(self, inputs, **kwargs)\u001B[0m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    125\u001B[0m \u001B[38;5;124;03mClassify the text(s) given as inputs.\u001B[39;00m\n\u001B[0;32m    126\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    156\u001B[0m \u001B[38;5;124;03m    If `top_k` is used, one such dictionary is returned per label.\u001B[39;00m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    158\u001B[0m inputs \u001B[38;5;241m=\u001B[39m (inputs,)\n\u001B[1;32m--> 159\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    160\u001B[0m \u001B[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001B[39;00m\n\u001B[0;32m    161\u001B[0m _legacy \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtop_k\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m kwargs\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\SocialMediaMining\\Lib\\site-packages\\transformers\\pipelines\\base.py:1349\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1345\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m can_use_iterator:\n\u001B[0;32m   1346\u001B[0m     final_iterator \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_iterator(\n\u001B[0;32m   1347\u001B[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001B[0;32m   1348\u001B[0m     )\n\u001B[1;32m-> 1349\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(final_iterator)\n\u001B[0;32m   1350\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n\u001B[0;32m   1351\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\SocialMediaMining\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:124\u001B[0m, in \u001B[0;36mPipelineIterator.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader_batch_item()\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# We're out of items within a batch\u001B[39;00m\n\u001B[1;32m--> 124\u001B[0m item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miterator)\n\u001B[0;32m    125\u001B[0m processed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfer(item, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams)\n\u001B[0;32m    126\u001B[0m \u001B[38;5;66;03m# We now have a batch of \"inferred things\".\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\SocialMediaMining\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py:125\u001B[0m, in \u001B[0;36mPipelineIterator.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# We're out of items within a batch\u001B[39;00m\n\u001B[0;32m    124\u001B[0m item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miterator)\n\u001B[1;32m--> 125\u001B[0m processed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfer(item, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams)\n\u001B[0;32m    126\u001B[0m \u001B[38;5;66;03m# We now have a batch of \"inferred things\".\u001B[39;00m\n\u001B[0;32m    127\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader_batch_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    128\u001B[0m     \u001B[38;5;66;03m# Try to infer the size of the batch\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\SocialMediaMining\\Lib\\site-packages\\transformers\\pipelines\\base.py:1276\u001B[0m, in \u001B[0;36mPipeline.forward\u001B[1;34m(self, model_inputs, **forward_params)\u001B[0m\n\u001B[0;32m   1274\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_inputs, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m   1275\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward(model_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mforward_params)\n\u001B[1;32m-> 1276\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_outputs, device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[0;32m   1277\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFramework \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not supported\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\SocialMediaMining\\Lib\\site-packages\\transformers\\pipelines\\base.py:1176\u001B[0m, in \u001B[0;36mPipeline._ensure_tensor_on_device\u001B[1;34m(self, inputs, device)\u001B[0m\n\u001B[0;32m   1173\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_ensure_tensor_on_device\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, device):\n\u001B[0;32m   1174\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(inputs, ModelOutput):\n\u001B[0;32m   1175\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m ModelOutput(\n\u001B[1;32m-> 1176\u001B[0m             {name: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(tensor, device) \u001B[38;5;28;01mfor\u001B[39;00m name, tensor \u001B[38;5;129;01min\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m   1177\u001B[0m         )\n\u001B[0;32m   1178\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(inputs, \u001B[38;5;28mdict\u001B[39m):\n\u001B[0;32m   1179\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m {name: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(tensor, device) \u001B[38;5;28;01mfor\u001B[39;00m name, tensor \u001B[38;5;129;01min\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mitems()}\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\SocialMediaMining\\Lib\\site-packages\\transformers\\pipelines\\base.py:1187\u001B[0m, in \u001B[0;36mPipeline._ensure_tensor_on_device\u001B[1;34m(self, inputs, device)\u001B[0m\n\u001B[0;32m   1185\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(item, device) \u001B[38;5;28;01mfor\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m inputs])\n\u001B[0;32m   1186\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(inputs, torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m-> 1187\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inputs\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1189\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m inputs\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T08:43:06.490556Z",
     "start_time": "2025-04-25T08:43:06.484551Z"
    }
   },
   "cell_type": "code",
   "source": "youtube_db.close()",
   "id": "b1322b21b8eb662e",
   "outputs": [],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
