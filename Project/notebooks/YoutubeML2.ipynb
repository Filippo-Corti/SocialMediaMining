{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-02T12:10:21.083250Z",
     "start_time": "2025-06-02T12:10:12.518152Z"
    }
   },
   "source": [
    "import multiprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import importlib\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import imblearn\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score\n",
    "from sklearn.model_selection import learning_curve, validation_curve, train_test_split, KFold, StratifiedKFold, \\\n",
    "    cross_val_score, GridSearchCV, RandomizedSearchCV, cross_validate, RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import recall_score, roc_curve, auc, precision_recall_curve\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from scipy.stats import loguniform, beta, uniform\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as IMBPipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from Project.utils.storage import youtube_db as db\n",
    "\n",
    "importlib.reload(db)\n",
    "\n",
    "trump_podcasts = [\n",
    "    \"xrFdHO7FH8w\",\n",
    "    \"blqIZGXWUpU\",\n",
    "    \"s11uIW7wi-E\",\n",
    "    \"vC5cHjcgt5g\",\n",
    "    \"G80iLTctFuY\",\n",
    "    \"qCbfTN-caFI\",\n",
    "    \"Ry1IjOft95c\",\n",
    "    \"S7BTdUaNQM8\",\n",
    "    \"1SsmPh8gCxU\",\n",
    "    \"-dmwG54QsKc\",\n",
    "    \"nwQil7tcImI\",\n",
    "    \"G9lXnwuZ2qs\",\n",
    "    \"hBMoPUAeLnY\"\n",
    "]\n",
    "\n",
    "harris_podcasts = [\n",
    "    \"_KCRsjPCiCI\",\n",
    "    \"bzThwqnQJDY\",\n",
    "    \"7L4sts7I3xI\",\n",
    "    \"pNbwMrBMGgE\",\n",
    "    \"Vu5yD3fu6A8\",\n",
    "]\n",
    "\n",
    "youtube_db = db.SQLiteYoutubeSaver(db_name='../db/youtube.db')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Filippo Corti\\miniconda3\\envs\\SocialMediaMining\\Lib\\site-packages\\cupy\\_environment.py:217: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T12:10:21.091170Z",
     "start_time": "2025-06-02T12:10:21.087032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NEUTRAL = 0\n",
    "REPUBLICAN = 1\n",
    "DEMOCRATIC = 2\n",
    "\n",
    "TRUMP = 0\n",
    "HARRIS = 1"
   ],
   "id": "b5086ee0c06f0fd4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T12:10:21.667457Z",
     "start_time": "2025-06-02T12:10:21.450909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "youtube_db.cursor.execute(f\"\"\"\n",
    "SELECT video_id, content, gemini_label\n",
    "FROM CommentAnalysis JOIN Comments on Comments.id = CommentAnalysis.id\n",
    "WHERE gemini_label IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "data = youtube_db.cursor.fetchall()\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = ['video_id', 'content', 'label']\n",
    "df['podcast_guest'] = ['Trump' if video_id in trump_podcasts else 'Harris' for video_id in df['video_id']]\n",
    "df['rep_label'] = [1 if l == 'Republican' else 0 for l in df['label']]\n",
    "df['dem_label'] = [1 if l == 'Democratic' else 0 for l in df['label']]\n",
    "df.drop('video_id', axis=1, inplace=True)\n",
    "\n",
    "df"
   ],
   "id": "e9815a0ed07d40e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 content       label  \\\n",
       "0                           Best Podcast of All-time? ðŸ¤”ðŸ”¥  Republican   \n",
       "1                                Definitely my favorite!  Republican   \n",
       "2                                         No, best guest  Republican   \n",
       "3                                               Probably     Neutral   \n",
       "4                                       Under 30 seconds     Neutral   \n",
       "...                                                  ...         ...   \n",
       "18973  @@leroyjetson2329Folks with Caribbean heritage...     Neutral   \n",
       "18974            I am only here for the comment section.     Neutral   \n",
       "18975                ðŸ˜…ðŸ˜‚ this comment section is trouble!     Neutral   \n",
       "18976  @@HI-DEF100 Iâ€™ve been looking for a positive c...  Republican   \n",
       "18977  @@Waydo2306 ive just been spamming â€œTrump 2024...  Republican   \n",
       "\n",
       "      podcast_guest  rep_label  dem_label  \n",
       "0             Trump          1          0  \n",
       "1             Trump          1          0  \n",
       "2             Trump          1          0  \n",
       "3             Trump          0          0  \n",
       "4             Trump          0          0  \n",
       "...             ...        ...        ...  \n",
       "18973        Harris          0          0  \n",
       "18974        Harris          0          0  \n",
       "18975        Harris          0          0  \n",
       "18976        Harris          1          0  \n",
       "18977        Harris          1          0  \n",
       "\n",
       "[18978 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>podcast_guest</th>\n",
       "      <th>rep_label</th>\n",
       "      <th>dem_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best Podcast of All-time? ðŸ¤”ðŸ”¥</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Trump</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Definitely my favorite!</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Trump</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No, best guest</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Trump</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Probably</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Trump</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Under 30 seconds</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Trump</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18973</th>\n",
       "      <td>@@leroyjetson2329Folks with Caribbean heritage...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18974</th>\n",
       "      <td>I am only here for the comment section.</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18975</th>\n",
       "      <td>ðŸ˜…ðŸ˜‚ this comment section is trouble!</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18976</th>\n",
       "      <td>@@HI-DEF100 Iâ€™ve been looking for a positive c...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18977</th>\n",
       "      <td>@@Waydo2306 ive just been spamming â€œTrump 2024...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18978 rows Ã— 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T12:10:21.732204Z",
     "start_time": "2025-06-02T12:10:21.726671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = df[['content', 'podcast_guest']]\n",
    "\n",
    "y_rep = df['rep_label']\n",
    "y_dem = df['dem_label']"
   ],
   "id": "19df08f2c1307171",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T12:10:21.812743Z",
     "start_time": "2025-06-02T12:10:21.797943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_rep, X_test_rep, y_train_rep, y_test_rep = train_test_split(\n",
    "    X, y_rep, test_size=0.2, stratify=y_rep, random_state=42, shuffle=True\n",
    ")"
   ],
   "id": "8c8dd04101b1e850",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T12:10:21.853995Z",
     "start_time": "2025-06-02T12:10:21.848091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SpacyVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model='en_core_web_md'):\n",
    "        self.model = model\n",
    "        self.nlp = None\n",
    "\n",
    "    def fit(self, X, y=None):  # Does nothing (only loads model)\n",
    "        self.nlp = spacy.load(self.model)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):  # Transforms with nlp(content)\n",
    "        return np.vstack([doc.vector for doc in self.nlp.pipe(X['content'], batch_size=64, n_process=3)])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('spacy_vect', SpacyVectorTransformer(), ['content']),\n",
    "        ('guest_ohe', OneHotEncoder(drop='first'), ['podcast_guest']),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def get_pipeline(): # Necessary to create two separate pipelines\n",
    "    return IMBPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('sampler', None),\n",
    "        ('dim_reduction', None),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ])"
   ],
   "id": "2d92abb51772bae3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T12:10:56.328551Z",
     "start_time": "2025-06-02T12:10:56.318116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "precision_scorer = make_scorer(f1_score, zero_division=0)\n",
    "\n",
    "sampler_configs = [\n",
    "    {\n",
    "        'sampler': [SMOTE()],\n",
    "        'sampler__sampling_strategy': ['minority', 0.9]\n",
    "    },\n",
    "    {\n",
    "        'sampler': [RandomOverSampler()],\n",
    "        'sampler__sampling_strategy': ['minority', 0.9]\n",
    "    }\n",
    "]\n",
    "\n",
    "dim_reduction_configs = [\n",
    "    {\n",
    "        'dim_reduction': [None]\n",
    "    },\n",
    "    {\n",
    "        'dim_reduction': [PCA()],\n",
    "        'dim_reduction__n_components': [0.7, 0.9]\n",
    "    },\n",
    "]\n",
    "\n",
    "classifier_configs = [\n",
    "    # {\n",
    "    #     'classifier': [SVC(probability=True, kernel='rbf')],\n",
    "    #     'classifier__C': loguniform(0.1, 10),\n",
    "    #     'classifier__class_weight': ['balanced']\n",
    "    # },\n",
    "    # {\n",
    "    #     'classifier': [LogisticRegression(solver='saga', max_iter=10000)],\n",
    "    #     'classifier__C': loguniform(0.01, 100),\n",
    "    #     'classifier__penalty': ['l1'],\n",
    "    #     'classifier__class_weight': ['balanced']\n",
    "    #\n",
    "    # },\n",
    "    {\n",
    "        'classifier': [RandomForestClassifier()],\n",
    "        'classifier__n_estimators': [100, 500],\n",
    "        'classifier__max_depth': [3, 5, 10],             # Limit depth\n",
    "        'classifier__min_samples_split': [2, 5, 10],      # Minimum samples to split\n",
    "        'classifier__min_samples_leaf': [1, 2, 4],        # Minimum samples per leaf\n",
    "        'classifier__max_features': ['sqrt', 'log2'],     # Features to consider\n",
    "        'classifier__bootstrap': [True, False]            # Bootstrap sampling\n",
    "    }\n",
    "]\n",
    "\n",
    "all_configs = [\n",
    "    dict(itertools.chain(*(e.items() for e in configuration)))\n",
    "    for configuration in itertools.product(\n",
    "        sampler_configs,\n",
    "        dim_reduction_configs,\n",
    "        classifier_configs\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"Total pipeline combinations: {len(all_configs)}\")"
   ],
   "id": "8588d29094373c8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pipeline combinations: 4\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-02T12:11:00.359428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rs_rep = RandomizedSearchCV(\n",
    "    get_pipeline(),\n",
    "    param_distributions=all_configs,\n",
    "    n_iter=25,\n",
    "    n_jobs=1,\n",
    "    cv=StratifiedKFold(n_splits=2, shuffle=True, random_state=42),\n",
    "    scoring=precision_scorer,\n",
    "    error_score='raise',\n",
    "    random_state=42,\n",
    "    verbose=3,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "nested_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "scores_rep = cross_validate(\n",
    "    rs_rep, X_train_rep, y_train_rep,\n",
    "    scoring=precision_scorer,\n",
    "    cv=nested_cv,\n",
    "    return_estimator=True,\n",
    "    n_jobs=1,\n",
    "    verbose=3\n",
    ")"
   ],
   "id": "cb4cf71cc35e2cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n",
      "[CV 1/2] END classifier=RandomForestClassifier(), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, dim_reduction=PCA(), dim_reduction__n_components=0.7, sampler=SMOTE(), sampler__sampling_strategy=minority;, score=(train=0.753, test=0.508) total time= 1.4min\n",
      "[CV 2/2] END classifier=RandomForestClassifier(), classifier__bootstrap=True, classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, dim_reduction=PCA(), dim_reduction__n_components=0.7, sampler=SMOTE(), sampler__sampling_strategy=minority;, score=(train=0.776, test=0.517) total time= 1.4min\n",
      "[CV 1/2] END classifier=RandomForestClassifier(), classifier__bootstrap=False, classifier__max_depth=10, classifier__max_features=log2, classifier__min_samples_leaf=4, classifier__min_samples_split=10, classifier__n_estimators=500, dim_reduction=PCA(), dim_reduction__n_components=0.9, sampler=SMOTE(), sampler__sampling_strategy=minority;, score=(train=0.870, test=0.506) total time= 1.5min\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T11:30:55.114498400Z",
     "start_time": "2025-06-02T11:27:41.350242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Define the pipeline\n",
    "pipeline = IMBPipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('sampler', RandomOverSampler(random_state=42)),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Parameter grid focused on controlling overfitting\n",
    "param_distributions = {\n",
    "    'sampler__sampling_strategy': ['minority', 1.0],  # Key strategies\n",
    "    'classifier__n_estimators': [500,],           # Tree count\n",
    "    'classifier__max_depth': [5],             # Limit depth\n",
    "    'classifier__min_samples_split': [2, 5, 10],      # Minimum samples to split\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],        # Minimum samples per leaf\n",
    "    'classifier__max_features': ['sqrt', 'log2'],     # Features to consider\n",
    "    'classifier__bootstrap': [True, False]            # Bootstrap sampling\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV setup\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=5,                          # Number of parameter combinations to try\n",
    "    scoring=precision_scorer,           # Use your precision scorer\n",
    "    error_score='raise',\n",
    "    cv=3,                               # 5-fold cross-validation\n",
    "    n_jobs=6,                          # Use all cores\n",
    "    verbose=3,                          # Detailed output\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit on training data (replace X_train, y_train with your actual data)\n",
    "random_search.fit(X_train_rep, y_train_rep)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best Parameters:\", random_search.best_params_)\n",
    "print(\"Best Precision Score:\", random_search.best_score_)"
   ],
   "id": "6ff098851472577e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV 1/3] END classifier__bootstrap=True, classifier__max_depth=5, classifier__max_features=sqrt, classifier__min_samples_leaf=1, classifier__min_samples_split=10, classifier__n_estimators=500, sampler__sampling_strategy=minority;, score=0.428 total time= 2.3min\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "best_estimators = scores_rep['estimator']\n",
    "\n",
    "# Evaluate on validation/test set for threshold optimization\n",
    "all_proba = []\n",
    "all_y_true = []\n",
    "\n",
    "print(\"Performance Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, estimator in enumerate(best_estimators):\n",
    "    print(f\"\\nFold {i+1}:\")\n",
    "    print(f\"CV Score: {scores_rep['test_score'][i]:.4f}\")\n",
    "\n",
    "    # Get predictions on test set (or use validation approach)\n",
    "    y_proba = estimator.predict_proba(X_test_rep)[:, 1]  # probabilities for positive class\n",
    "    y_pred_default = estimator.predict(X_test_rep)\n",
    "\n",
    "    all_proba.extend(y_proba)\n",
    "    all_y_true.extend(y_test_rep)\n",
    "\n",
    "    # Default threshold performance\n",
    "    default_precision = precision_score(y_test_rep, y_pred_default)\n",
    "    default_recall = recall_score(y_test_rep, y_pred_default)\n",
    "    default_f1 = f1_score(y_test_rep, y_pred_default)\n",
    "\n",
    "    print(f\"Default threshold (0.5) - Precision: {default_precision:.4f}, Recall: {default_recall:.4f}, F1: {default_f1:.4f}\")\n",
    "\n",
    "# Convert to arrays for analysis\n",
    "all_proba = np.array(all_proba)\n",
    "all_y_true = np.array(all_y_true)\n",
    "\n",
    "print(f\"\\nOverall CV Score: {scores_rep['test_score'].mean():.4f} Â± {scores_rep['test_score'].std():.4f}\")\n",
    "\n",
    "# Find optimal threshold\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"THRESHOLD OPTIMIZATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Method 1: Optimize for F1 score\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresh = (all_proba >= threshold).astype(int)\n",
    "    f1 = f1_score(all_y_true, y_pred_thresh)\n",
    "    precision = precision_score(all_y_true, y_pred_thresh)\n",
    "    recall = recall_score(all_y_true, y_pred_thresh)\n",
    "\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "# Best threshold for F1\n",
    "best_f1_idx = np.argmax(f1_scores)\n",
    "best_f1_threshold = thresholds[best_f1_idx]\n",
    "best_f1_score = f1_scores[best_f1_idx]\n",
    "\n",
    "print(f\"Best F1 Threshold: {best_f1_threshold:.3f}\")\n",
    "print(f\"Best F1 Score: {best_f1_score:.4f}\")\n",
    "print(f\"Precision at best F1: {precision_scores[best_f1_idx]:.4f}\")\n",
    "print(f\"Recall at best F1: {recall_scores[best_f1_idx]:.4f}\")\n",
    "\n",
    "# Method 2: ROC curve analysis\n",
    "fpr, tpr, roc_thresholds = roc_curve(all_y_true, all_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Find threshold closest to top-left corner (Youden's J statistic)\n",
    "j_scores = tpr - fpr\n",
    "best_j_idx = np.argmax(j_scores)\n",
    "best_roc_threshold = roc_thresholds[best_j_idx]\n",
    "\n",
    "print(f\"\\nBest ROC Threshold (Youden's J): {best_roc_threshold:.3f}\")\n",
    "\n",
    "y_pred_roc = (all_proba >= best_roc_threshold).astype(int)\n",
    "roc_precision = precision_score(all_y_true, y_pred_roc)\n",
    "roc_recall = recall_score(all_y_true, y_pred_roc)\n",
    "roc_f1 = f1_score(all_y_true, y_pred_roc)\n",
    "\n",
    "print(f\"ROC Threshold Performance - Precision: {roc_precision:.4f}, Recall: {roc_recall:.4f}, F1: {roc_f1:.4f}\")\n",
    "\n",
    "# Plotting\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# ROC Curve\n",
    "ax1.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "ax1.scatter(fpr[best_j_idx], tpr[best_j_idx], color='red', s=100, label=f'Best threshold = {best_roc_threshold:.3f}')\n",
    "ax1.set_xlim([0.0, 1.0])\n",
    "ax1.set_ylim([0.0, 1.05])\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.set_title('ROC Curve')\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision_pr, recall_pr, pr_thresholds = precision_recall_curve(all_y_true, all_proba)\n",
    "pr_auc = auc(recall_pr, precision_pr)\n",
    "\n",
    "ax2.plot(recall_pr, precision_pr, color='blue', lw=2, label=f'PR curve (AUC = {pr_auc:.3f})')\n",
    "ax2.set_xlabel('Recall')\n",
    "ax2.set_ylabel('Precision')\n",
    "ax2.set_title('Precision-Recall Curve')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "# Threshold vs Metrics\n",
    "ax3.plot(thresholds, f1_scores, 'g-', label='F1 Score', linewidth=2)\n",
    "ax3.plot(thresholds, precision_scores, 'b-', label='Precision', linewidth=2)\n",
    "ax3.plot(thresholds, recall_scores, 'r-', label='Recall', linewidth=2)\n",
    "ax3.axvline(best_f1_threshold, color='black', linestyle='--', alpha=0.7, label=f'Best F1 threshold = {best_f1_threshold:.3f}')\n",
    "ax3.set_xlabel('Threshold')\n",
    "ax3.set_ylabel('Score')\n",
    "ax3.set_title('Metrics vs Threshold')\n",
    "ax3.legend()\n",
    "ax3.grid(True)\n",
    "\n",
    "# Probability Distribution\n",
    "ax4.hist(all_proba[all_y_true == 0], bins=30, alpha=0.7, label='Negative Class', color='red')\n",
    "ax4.hist(all_proba[all_y_true == 1], bins=30, alpha=0.7, label='Positive Class', color='blue')\n",
    "ax4.axvline(best_f1_threshold, color='black', linestyle='--', label=f'Best F1 threshold = {best_f1_threshold:.3f}')\n",
    "ax4.axvline(0.5, color='gray', linestyle=':', label='Default threshold = 0.5')\n",
    "ax4.set_xlabel('Predicted Probability')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_title('Probability Distribution by Class')\n",
    "ax4.legend()\n",
    "ax4.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "\n",
    "# Final recommendation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RECOMMENDATION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Recommended threshold: {best_f1_threshold:.3f} (optimized for F1-score)\")\n",
    "print(f\"Expected performance: Precision={precision_scores[best_f1_idx]:.4f}, Recall={recall_scores[best_f1_idx]:.4f}, F1={best_f1_score:.4f}\")"
   ],
   "id": "ac0894044ee3736d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
