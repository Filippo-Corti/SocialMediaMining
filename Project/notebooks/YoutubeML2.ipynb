{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-02T15:36:28.607428Z",
     "start_time": "2025-06-02T15:36:19.279942Z"
    }
   },
   "source": [
    "import multiprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import importlib\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import imblearn\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score\n",
    "from sklearn.model_selection import learning_curve, validation_curve, train_test_split, KFold, StratifiedKFold, \\\n",
    "    cross_val_score, GridSearchCV, RandomizedSearchCV, cross_validate, RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import recall_score, roc_curve, auc, precision_recall_curve\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from scipy.stats import loguniform, beta, uniform\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline as IMBPipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from Project.utils.storage import youtube_db as db\n",
    "\n",
    "importlib.reload(db)\n",
    "\n",
    "trump_podcasts = [\n",
    "    \"xrFdHO7FH8w\",\n",
    "    \"blqIZGXWUpU\",\n",
    "    \"s11uIW7wi-E\",\n",
    "    \"vC5cHjcgt5g\",\n",
    "    \"G80iLTctFuY\",\n",
    "    \"qCbfTN-caFI\",\n",
    "    \"Ry1IjOft95c\",\n",
    "    \"S7BTdUaNQM8\",\n",
    "    \"1SsmPh8gCxU\",\n",
    "    \"-dmwG54QsKc\",\n",
    "    \"nwQil7tcImI\",\n",
    "    \"G9lXnwuZ2qs\",\n",
    "    \"hBMoPUAeLnY\"\n",
    "]\n",
    "\n",
    "harris_podcasts = [\n",
    "    \"_KCRsjPCiCI\",\n",
    "    \"bzThwqnQJDY\",\n",
    "    \"7L4sts7I3xI\",\n",
    "    \"pNbwMrBMGgE\",\n",
    "    \"Vu5yD3fu6A8\",\n",
    "]\n",
    "\n",
    "youtube_db = db.SQLiteYoutubeSaver(db_name='../db/youtube.db')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Filippo Corti\\miniconda3\\envs\\SocialMediaMining\\Lib\\site-packages\\cupy\\_environment.py:217: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T15:36:29.118403Z",
     "start_time": "2025-06-02T15:36:29.114274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NEUTRAL = 0\n",
    "REPUBLICAN = 1\n",
    "DEMOCRATIC = 2\n",
    "\n",
    "TRUMP = 0\n",
    "HARRIS = 1"
   ],
   "id": "b5086ee0c06f0fd4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T15:36:30.074046Z",
     "start_time": "2025-06-02T15:36:29.142329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "youtube_db.cursor.execute(f\"\"\"\n",
    "SELECT video_id, content, gemini_label\n",
    "FROM CommentAnalysis JOIN Comments on Comments.id = CommentAnalysis.id\n",
    "WHERE gemini_label IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "data = youtube_db.cursor.fetchall()\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.columns = ['video_id', 'content', 'label']\n",
    "df['podcast_guest'] = ['Trump' if video_id in trump_podcasts else 'Harris' for video_id in df['video_id']]\n",
    "df['rep_label'] = [1 if l == 'Republican' else 0 for l in df['label']]\n",
    "df['dem_label'] = [1 if l == 'Democratic' else 0 for l in df['label']]\n",
    "df.drop('video_id', axis=1, inplace=True)\n",
    "\n",
    "df"
   ],
   "id": "e9815a0ed07d40e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 content       label  \\\n",
       "0                           Best Podcast of All-time? ðŸ¤”ðŸ”¥  Republican   \n",
       "1                                Definitely my favorite!  Republican   \n",
       "2                                         No, best guest  Republican   \n",
       "3                                               Probably     Neutral   \n",
       "4                                       Under 30 seconds     Neutral   \n",
       "...                                                  ...         ...   \n",
       "18973  @@leroyjetson2329Folks with Caribbean heritage...     Neutral   \n",
       "18974            I am only here for the comment section.     Neutral   \n",
       "18975                ðŸ˜…ðŸ˜‚ this comment section is trouble!     Neutral   \n",
       "18976  @@HI-DEF100 Iâ€™ve been looking for a positive c...  Republican   \n",
       "18977  @@Waydo2306 ive just been spamming â€œTrump 2024...  Republican   \n",
       "\n",
       "      podcast_guest  rep_label  dem_label  \n",
       "0             Trump          1          0  \n",
       "1             Trump          1          0  \n",
       "2             Trump          1          0  \n",
       "3             Trump          0          0  \n",
       "4             Trump          0          0  \n",
       "...             ...        ...        ...  \n",
       "18973        Harris          0          0  \n",
       "18974        Harris          0          0  \n",
       "18975        Harris          0          0  \n",
       "18976        Harris          1          0  \n",
       "18977        Harris          1          0  \n",
       "\n",
       "[18978 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>podcast_guest</th>\n",
       "      <th>rep_label</th>\n",
       "      <th>dem_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Best Podcast of All-time? ðŸ¤”ðŸ”¥</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Trump</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Definitely my favorite!</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Trump</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No, best guest</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Trump</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Probably</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Trump</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Under 30 seconds</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Trump</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18973</th>\n",
       "      <td>@@leroyjetson2329Folks with Caribbean heritage...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18974</th>\n",
       "      <td>I am only here for the comment section.</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18975</th>\n",
       "      <td>ðŸ˜…ðŸ˜‚ this comment section is trouble!</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Harris</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18976</th>\n",
       "      <td>@@HI-DEF100 Iâ€™ve been looking for a positive c...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18977</th>\n",
       "      <td>@@Waydo2306 ive just been spamming â€œTrump 2024...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>Harris</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18978 rows Ã— 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T15:39:07.449151Z",
     "start_time": "2025-06-02T15:39:07.443360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = df[['content', 'podcast_guest']]\n",
    "\n",
    "y_rep = df['rep_label']\n",
    "y_dem = df['dem_label']"
   ],
   "id": "19df08f2c1307171",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T15:39:09.560300Z",
     "start_time": "2025-06-02T15:39:09.547124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train_rep, X_test_rep, y_train_rep, y_test_rep = train_test_split(\n",
    "    X, y_rep, test_size=0.2, stratify=y_rep, random_state=42, shuffle=True\n",
    ")"
   ],
   "id": "8c8dd04101b1e850",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T15:39:11.382723Z",
     "start_time": "2025-06-02T15:39:11.375526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SpacyVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model='en_core_web_md'):\n",
    "        self.model = model\n",
    "        self.nlp = None\n",
    "\n",
    "    def fit(self, X, y=None):  # Does nothing (only loads model)\n",
    "        self.nlp = spacy.load(self.model)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):  # Transforms with nlp(content)\n",
    "        return np.vstack([doc.vector for doc in self.nlp.pipe(X['content'], batch_size=64, n_process=3)])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('spacy_vect', SpacyVectorTransformer(), ['content']),\n",
    "        ('guest_ohe', OneHotEncoder(drop='first'), ['podcast_guest']),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def get_pipeline(): # Necessary to create two separate pipelines\n",
    "    return IMBPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('sampler', None),\n",
    "        ('dim_reduction', None),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ])"
   ],
   "id": "2d92abb51772bae3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-02T17:17:35.906077Z",
     "start_time": "2025-06-02T17:17:35.896545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scoring = {\n",
    "    'f1': make_scorer(f1_score, zero_division=0),\n",
    "    'precision': make_scorer(precision_score, zero_division=0),\n",
    "    'recall': make_scorer(recall_score, zero_division=0),\n",
    "    'roc_auc': make_scorer(roc_auc_score)\n",
    "}\n",
    "\n",
    "sampler_configs = [\n",
    "    {\n",
    "        'sampler': [None],\n",
    "    },\n",
    "    # {\n",
    "    #     'sampler': [SMOTE(random_state=42)],\n",
    "    #     'sampler__sampling_strategy': [0.8, 1.0]\n",
    "    # },\n",
    "]\n",
    "\n",
    "dim_reduction_configs = [\n",
    "    {\n",
    "        'dim_reduction': [None]\n",
    "    },\n",
    "    # {\n",
    "    #     'dim_reduction': [PCA(random_state=42)],\n",
    "    #     'dim_reduction__n_components': [0.9]\n",
    "    # },\n",
    "]\n",
    "\n",
    "classifier_configs = [\n",
    "    {\n",
    "        'classifier': [RandomForestClassifier(random_state=42)],\n",
    "        'classifier__n_estimators': [50],\n",
    "        'classifier__max_depth': [12, 14],\n",
    "        'classifier__min_samples_split': [15, 25],\n",
    "        'classifier__min_samples_leaf': [30, 50],\n",
    "        'classifier__max_features': [0.5, 'sqrt'],\n",
    "        'classifier__class_weight': ['balanced', {0: 1, 1: 2}, {0: 1, 1: 4}],\n",
    "    },\n",
    "    {\n",
    "        'classifier': [LogisticRegression(solver='liblinear', max_iter=10000, random_state=42)],\n",
    "        'classifier__C': [0.01, 0.1, 1.0],\n",
    "        'classifier__penalty': ['l1', 'l2'],\n",
    "        'classifier__class_weight': ['balanced', {0: 1, 1: 2}, {0: 1, 1: 4}]\n",
    "    }\n",
    "]\n",
    "\n",
    "all_configs = [\n",
    "    dict(itertools.chain(*(e.items() for e in configuration)))\n",
    "    for configuration in itertools.product(\n",
    "        sampler_configs,\n",
    "        dim_reduction_configs,\n",
    "        classifier_configs\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"Total pipeline combinations: {len(all_configs)}\")"
   ],
   "id": "8588d29094373c8a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pipeline combinations: 2\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "baseline_pipeline = get_pipeline()\n",
    "baseline_pipeline.set_params(\n",
    "    sampler=None,\n",
    "    dim_reduction=None,\n",
    "    classifier=RandomForestClassifier(\n",
    "        n_estimators=50,\n",
    "        max_depth=8,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "baseline_scores = cross_val_score(\n",
    "    baseline_pipeline, X_train_rep, y_train_rep,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='f1'\n",
    ")\n",
    "print(f\"Baseline RF F1: {baseline_scores.mean():.3f} (+/- {baseline_scores.std() * 2:.3f})\") # Result was Baseline RF F1: 0.548 (+/- 0.011)"
   ],
   "id": "f2177a8952a6d248",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-02T17:17:43.726811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rs_rep = RandomizedSearchCV(\n",
    "    get_pipeline(),\n",
    "    param_distributions=all_configs,\n",
    "    n_iter=10,\n",
    "    n_jobs=1,\n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "    scoring=scoring,\n",
    "    error_score='raise',\n",
    "    refit='precision',\n",
    "    random_state=42,\n",
    "    verbose=3,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "rs_rep.fit(X_train_rep, y_train_rep)\n",
    "\n",
    "# nested_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#\n",
    "# scores_rep = cross_validate(\n",
    "#     rs_rep, X_train_rep, y_train_rep,\n",
    "#     scoring=scoring,\n",
    "#     cv=nested_cv,\n",
    "#     return_estimator=True,\n",
    "#     n_jobs=1,\n",
    "#     verbose=3\n",
    "# )"
   ],
   "id": "cb4cf71cc35e2cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "best_estimators = scores_rep['estimator']\n",
    "\n",
    "# Evaluate on validation/test set for threshold optimization\n",
    "all_proba = []\n",
    "all_y_true = []\n",
    "\n",
    "print(\"Performance Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i, estimator in enumerate(best_estimators):\n",
    "    print(f\"\\nFold {i+1}:\")\n",
    "    print(f\"CV Score: {scores_rep['test_score'][i]:.4f}\")\n",
    "\n",
    "    # Get predictions on test set (or use validation approach)\n",
    "    y_proba = estimator.predict_proba(X_test_rep)[:, 1]  # probabilities for positive class\n",
    "    y_pred_default = estimator.predict(X_test_rep)\n",
    "\n",
    "    all_proba.extend(y_proba)\n",
    "    all_y_true.extend(y_test_rep)\n",
    "\n",
    "    # Default threshold performance\n",
    "    default_precision = precision_score(y_test_rep, y_pred_default)\n",
    "    default_recall = recall_score(y_test_rep, y_pred_default)\n",
    "    default_f1 = f1_score(y_test_rep, y_pred_default)\n",
    "\n",
    "    print(f\"Default threshold (0.5) - Precision: {default_precision:.4f}, Recall: {default_recall:.4f}, F1: {default_f1:.4f}\")\n",
    "\n",
    "# Convert to arrays for analysis\n",
    "all_proba = np.array(all_proba)\n",
    "all_y_true = np.array(all_y_true)\n",
    "\n",
    "print(f\"\\nOverall CV Score: {scores_rep['test_score'].mean():.4f} Â± {scores_rep['test_score'].std():.4f}\")\n",
    "\n",
    "# Find optimal threshold\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"THRESHOLD OPTIMIZATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Method 1: Optimize for F1 score\n",
    "thresholds = np.arange(0.1, 0.9, 0.05)\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresh = (all_proba >= threshold).astype(int)\n",
    "    f1 = f1_score(all_y_true, y_pred_thresh)\n",
    "    precision = precision_score(all_y_true, y_pred_thresh)\n",
    "    recall = recall_score(all_y_true, y_pred_thresh)\n",
    "\n",
    "    f1_scores.append(f1)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "# Best threshold for F1\n",
    "best_f1_idx = np.argmax(f1_scores)\n",
    "best_f1_threshold = thresholds[best_f1_idx]\n",
    "best_f1_score = f1_scores[best_f1_idx]\n",
    "\n",
    "print(f\"Best F1 Threshold: {best_f1_threshold:.3f}\")\n",
    "print(f\"Best F1 Score: {best_f1_score:.4f}\")\n",
    "print(f\"Precision at best F1: {precision_scores[best_f1_idx]:.4f}\")\n",
    "print(f\"Recall at best F1: {recall_scores[best_f1_idx]:.4f}\")\n",
    "\n",
    "# Method 2: ROC curve analysis\n",
    "fpr, tpr, roc_thresholds = roc_curve(all_y_true, all_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Find threshold closest to top-left corner (Youden's J statistic)\n",
    "j_scores = tpr - fpr\n",
    "best_j_idx = np.argmax(j_scores)\n",
    "best_roc_threshold = roc_thresholds[best_j_idx]\n",
    "\n",
    "print(f\"\\nBest ROC Threshold (Youden's J): {best_roc_threshold:.3f}\")\n",
    "\n",
    "y_pred_roc = (all_proba >= best_roc_threshold).astype(int)\n",
    "roc_precision = precision_score(all_y_true, y_pred_roc)\n",
    "roc_recall = recall_score(all_y_true, y_pred_roc)\n",
    "roc_f1 = f1_score(all_y_true, y_pred_roc)\n",
    "\n",
    "print(f\"ROC Threshold Performance - Precision: {roc_precision:.4f}, Recall: {roc_recall:.4f}, F1: {roc_f1:.4f}\")\n",
    "\n",
    "# Plotting\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# ROC Curve\n",
    "ax1.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "ax1.scatter(fpr[best_j_idx], tpr[best_j_idx], color='red', s=100, label=f'Best threshold = {best_roc_threshold:.3f}')\n",
    "ax1.set_xlim([0.0, 1.0])\n",
    "ax1.set_ylim([0.0, 1.05])\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.set_title('ROC Curve')\n",
    "ax1.legend(loc=\"lower right\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision_pr, recall_pr, pr_thresholds = precision_recall_curve(all_y_true, all_proba)\n",
    "pr_auc = auc(recall_pr, precision_pr)\n",
    "\n",
    "ax2.plot(recall_pr, precision_pr, color='blue', lw=2, label=f'PR curve (AUC = {pr_auc:.3f})')\n",
    "ax2.set_xlabel('Recall')\n",
    "ax2.set_ylabel('Precision')\n",
    "ax2.set_title('Precision-Recall Curve')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "# Threshold vs Metrics\n",
    "ax3.plot(thresholds, f1_scores, 'g-', label='F1 Score', linewidth=2)\n",
    "ax3.plot(thresholds, precision_scores, 'b-', label='Precision', linewidth=2)\n",
    "ax3.plot(thresholds, recall_scores, 'r-', label='Recall', linewidth=2)\n",
    "ax3.axvline(best_f1_threshold, color='black', linestyle='--', alpha=0.7, label=f'Best F1 threshold = {best_f1_threshold:.3f}')\n",
    "ax3.set_xlabel('Threshold')\n",
    "ax3.set_ylabel('Score')\n",
    "ax3.set_title('Metrics vs Threshold')\n",
    "ax3.legend()\n",
    "ax3.grid(True)\n",
    "\n",
    "# Probability Distribution\n",
    "ax4.hist(all_proba[all_y_true == 0], bins=30, alpha=0.7, label='Negative Class', color='red')\n",
    "ax4.hist(all_proba[all_y_true == 1], bins=30, alpha=0.7, label='Positive Class', color='blue')\n",
    "ax4.axvline(best_f1_threshold, color='black', linestyle='--', label=f'Best F1 threshold = {best_f1_threshold:.3f}')\n",
    "ax4.axvline(0.5, color='gray', linestyle=':', label='Default threshold = 0.5')\n",
    "ax4.set_xlabel('Predicted Probability')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_title('Probability Distribution by Class')\n",
    "ax4.legend()\n",
    "ax4.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"PR AUC: {pr_auc:.4f}\")\n",
    "\n",
    "# Final recommendation\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RECOMMENDATION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Recommended threshold: {best_f1_threshold:.3f} (optimized for F1-score)\")\n",
    "print(f\"Expected performance: Precision={precision_scores[best_f1_idx]:.4f}, Recall={recall_scores[best_f1_idx]:.4f}, F1={best_f1_score:.4f}\")"
   ],
   "id": "ac0894044ee3736d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Training with Best Estimator\n",
    "\n",
    "# Plotting the Learning Curve??\n",
    "\n",
    "# Do the same for other model\n"
   ],
   "id": "646c93ffcf483a52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "befa80d9c679d43d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
